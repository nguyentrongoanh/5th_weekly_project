{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign Sentiment and reviews column \n",
    "reviews = df_train['Phrase']\n",
    "sentiment = df_train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize sentiment data\n",
    "fig = plt.figure()\n",
    "axes1 = fig.add_subplot(1, 1, 1)\n",
    "axes1.hist(sentiment)\n",
    "axes1.set_xlabel('Sentiment')\n",
    "axes1.set_ylabel('Count')\n",
    "plt.xticks(range(5))\n",
    "# Most of the review is \"neutral\", what prediction i can make base on this data? \n",
    "# Maybe it shows that the data is unbalance so we cannot evaluate the model base on accuracy?\n",
    "# or most of words in the phrase represent for the neutral sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words in the review\n",
    "vocab = Counter()\n",
    "for phrase in reviews:\n",
    "    for word in phrase.split():\n",
    "        vocab[word] += 1\n",
    "\n",
    "# Quick look at the most common word\n",
    "vocab.most_common()\n",
    "\n",
    "# There is some strange word like: -RRB-, what does it mean?\n",
    "# No result from google, must find the context where this word is in.\n",
    "# Luckily, it's in the second phrase of the dataset\n",
    "reviews.loc[1]\n",
    "# Combine with the result on google it's the LEFT ROUND BRACKET and RIGHT ROUND BRACKET, should get rid of them\n",
    "# There're also digit character in the data, not much information from this digit, get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove -LRB- or -RRB-\n",
    "def remove_brackets(text):\n",
    "    for word in text.split():\n",
    "        if word == '-LRB-' or word == '-RRB-':\n",
    "            text = text.replace(word, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove -LRB- or -RRB- in reviews\n",
    "reviews = reviews.apply(remove_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove special character and digits (reuse from Quaan's code)\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # Also Convert to lower case\n",
    "#     text = (re.sub('[0-9]', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special character and digits\n",
    "# reviews = reviews.apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download list of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    filtered_word = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stop_words:\n",
    "            filtered_word.append(word)\n",
    "    return ' '.join(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords before tokenizer to avoid warning while stemming\n",
    "reviews = reviews.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stemming (reuse Quan's code)\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Split a text into list of words and apply stemming technic\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression using tfidf\n",
    "X_train = reviews\n",
    "y_train = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms data into matrix\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "# instantiate estimator\n",
    "clf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "# training model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on training set\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "# Your code here\n",
    "predictions = clf.predict(X_train)\n",
    "print('accuracy:',accuracy_score(y_train,predictions))\n",
    "print('confusion matrix:\\n',confusion_matrix(y_train,predictions))\n",
    "print('classification report:\\n',classification_report(y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test_set\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "X_test = df_test['Phrase']\n",
    "# Now apply those above metrics to evaluate your model\n",
    "# Your code here\n",
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add result in test_set\n",
    "df_test['Sentiment'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_test.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    print(f'{X_test[i]} --> 0, 1, 2, 3, 4, 5 = {preds[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
